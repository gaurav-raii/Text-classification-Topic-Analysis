{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AdvancedAnalytics import TextAnalytics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for Text Preprocessing \n",
    "import string\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet as wn \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn methods for Preparing the Term-Doc Matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# sklearn methods for Extracting Topics using the Term-Doc Matrix \n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase column width to let pandy read large text columns \n",
    "pd.set_option('max_colwidth', 32000)\n",
    "\n",
    "# Read California Chardonnay Reviews \n",
    "df = pd.read_excel(\"C:/Users/gaura/Desktop/stat 656/week 10/CaliforniaCabernet.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup program constants and reviews \n",
    "n_reviews = len(df['description']) \n",
    "s_words = 'english' \n",
    "ngram = (1,2) \n",
    "reviews = df['description']\n",
    "\n",
    "# Constants \n",
    "m_features = None # default is None \n",
    "n_topics = 9 # number of topics \n",
    "max_iter = 10 # maximum number of iterations \n",
    "max_df = 0.5 # max proportion of docs/reviews allowed for a term \n",
    "learning_offset = 10. # default is 10 \n",
    "learning_method = 'online' # alternative is 'batch' for large files \n",
    "tf_matrix='tfidf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews..... 13135\n",
      "Number of Terms.......  5595\n",
      "\n",
      "Terms with Highest Frequency:\n",
      "wine            7439\n",
      "tannin          5134\n",
      "cherry          5123\n",
      "cabernet        4968\n",
      "oak             4670\n",
      "black           4596\n",
      "currant         4404\n",
      "dry             4146\n",
      "fruit           3543\n",
      "rich            2947\n"
     ]
    }
   ],
   "source": [
    "# Create the Review by Term Frequency Matrix using Custom Analyzer \n",
    "# max_df is a limit for terms. If a term has more than this \n",
    "# proportion of documents then that term is dropped. \n",
    "\n",
    "ta = TextAnalytics() \n",
    "cv = CountVectorizer(max_df=max_df, min_df=2, max_features=m_features,analyzer=ta.my_analyzer) \n",
    "tf = cv.fit_transform(reviews) \n",
    "terms = cv.get_feature_names() \n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Reviews\", len(reviews))) \n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Terms\", len(terms)))\n",
    "\n",
    "term_sums = tf.sum(axis=0) \n",
    "term_counts = [] \n",
    "for i in range(len(terms)):\n",
    "    term_counts.append([terms[i], term_sums[0,i]]) \n",
    "def sortSecond(e):\n",
    "    return e[1] \n",
    "term_counts.sort(key=sortSecond, reverse=True) \n",
    "print(\"\\nTerms with Highest Frequency:\") \n",
    "for i in range(10):\n",
    "    print('{:<15s}{:>5d}'.format(term_counts[i][0], term_counts[i][1])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Constructing Term/Frequency Matrix using TF-IDF\n",
      "The Term/Frequency matrix has 13135  rows, and 5595  columns.\n",
      "The Term list has 5595  terms.\n",
      "\n",
      "Terms with Highest TF-IDF Scores:\n",
      "wine           12619.14\n",
      "cabernet       10151.85\n",
      "tannin         10083.79\n",
      "cherry         10070.38\n",
      "black           9932.89\n",
      "oak             9651.13\n",
      "currant         9241.95\n",
      "dry             9122.76\n",
      "fruit           8436.35\n",
      "rich            7429.52\n"
     ]
    }
   ],
   "source": [
    "# Construct the TF/IDF matrix from the Term Frequency matrix \n",
    "print(\"\\nConstructing Term/Frequency Matrix using TF-IDF\") \n",
    "# Default for norm is 'l2', use norm=None to supress \n",
    "tfidf_vect = TfidfTransformer(norm=None, use_idf=True) #set norm=None \n",
    "# tf matrix is (n_reviews)x(m_terms) \n",
    "tf = tfidf_vect.fit_transform(tf)\n",
    "# Display the terms with the largest TFIDF value \n",
    "term_idf_sums = tf.sum(axis=0) \n",
    "term_idf_scores = [] \n",
    "for i in range(len(terms)):\n",
    "    term_idf_scores.append([terms[i], term_idf_sums[0,i]]) \n",
    "print(\"The Term/Frequency matrix has\", tf.shape[0], \" rows, and\", tf.shape[1], \" columns.\") \n",
    "print(\"The Term list has\", len(terms), \" terms.\") \n",
    "term_idf_scores.sort(key=sortSecond, reverse=True) \n",
    "print(\"\\nTerms with Highest TF-IDF Scores:\") \n",
    "for i in range(10):\n",
    "    j = i\n",
    "    print('{:<15s}{:>8.2f}'.format(term_idf_scores[j][0],  term_idf_scores[j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = LatentDirichletAllocation(n_components=n_topics, max_iter=max_iter,\\\n",
    "                               learning_method=learning_method, \\\n",
    "                               learning_offset=learning_offset, \\\n",
    "                                random_state=12345) \n",
    "U = uv.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** GENERATED TOPICS **********\n",
      "Topic #1: \n",
      "+valley        +dry           +napa          +vineyard      +everyday      \n",
      "+cabernet      +nicely        +wine          +thin          +grape         \n",
      "+source        +drink         +pleasant      +tannin        +supple        \n",
      "\n",
      "Topic #2: \n",
      "+wrap          +mark          +show          +mint          +bordeaux      \n",
      "+keep          +wine          +tannin        +spice         +especially    \n",
      "+cherry        +napa          +know          +valley        +acidity       \n",
      "\n",
      "Topic #3: \n",
      "+go            +frame         +bottle        +soften        +produce       \n",
      "+case          +may           +wine          +sour          +production    \n",
      "+mountain      +time          +vintage       +graphite      +develop       \n",
      "\n",
      "Topic #4: \n",
      "+acid          +fruit         +finish        +wine          +note          \n",
      "+somewhat      +tannin        +dry           +wood          +hot           \n",
      "+black         +cherry        +raisin        +violet        +ageability    \n",
      "\n",
      "Topic #5: \n",
      "+body          +full          +palate        +wine          +black         \n",
      "+red           +finish        +plum          +merlot        +fruit         \n",
      "+verdot        +blend         +nose          +petit         +medium        \n",
      "\n",
      "Topic #6: \n",
      "+nice          +dry           +currant       +cab           +cabernet      \n",
      "+simple        +tough         +show          +hold          +good          \n",
      "+balance       +price         +style         +wine          +tannin        \n",
      "\n",
      "Topic #7: \n",
      "+hard          +year          +young         +give          +age           \n",
      "+cellar        +currant       +tannic        +decant        +tannin        \n",
      "+wine          +black         +core          +want          +try           \n",
      "\n",
      "Topic #8: \n",
      "+oak           +rich          +ripe          +chocolate     +sweet         \n",
      "+cabernet      +smoky         +drink         +year          +next          \n",
      "+currant       +new           +soft          +cherry        +mouth         \n",
      "\n",
      "Topic #9: \n",
      "+sweet         +cherry        +like          +jammy         +almost        \n",
      "+taste         +easy          +raspberry     +soft          +drinking      \n",
      "+oak           +fruit         +green         +drinkable     +ripe          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the topic selections \n",
    "print(\"\\n********** GENERATED TOPICS **********\") \n",
    "TextAnalytics.display_topics(uv.components_, terms, n_terms=15, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store topic selection for each doc in topics[] \n",
    "topics = [0] * n_reviews \n",
    "for i in range(n_reviews):\n",
    "    max = abs(U[i][0])\n",
    "    topics[i] = 0\n",
    "    for j in range(n_topics):\n",
    "        x = abs(U[i][j])\n",
    "        if x > max:\n",
    "            max = x\n",
    "            topics[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Store Topic Scores in rev_score *** \n",
    "rev_scores = [] \n",
    "for i in range(n_reviews):\n",
    "    u = [0] * (n_topics+1)\n",
    "    u[0] = topics[i]\n",
    "    for j in range(n_topics):\n",
    "        u[j+1] = U[i][j]\n",
    "    rev_scores.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup review topics in new pandas dataframe 'df_rev' \n",
    "cols = [\"topic\"] \n",
    "for i in range(n_topics):\n",
    "    s = \"T\"+str(i+1)\n",
    "    cols.append(s) \n",
    "df_rev = pd.DataFrame.from_records(rev_scores, columns=cols) \n",
    "df = df.join(df_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>Avg_price</th>\n",
       "      <th>Avg_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.688419</td>\n",
       "      <td>88.777064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51.176056</td>\n",
       "      <td>89.244780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>66.510903</td>\n",
       "      <td>89.422360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54.037752</td>\n",
       "      <td>87.408734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60.554520</td>\n",
       "      <td>89.281855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>51.037406</td>\n",
       "      <td>89.003111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>63.092680</td>\n",
       "      <td>89.463496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>57.049152</td>\n",
       "      <td>89.459365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>42.237874</td>\n",
       "      <td>86.087905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  Avg_price  Avg_points\n",
       "0        0  51.688419   88.777064\n",
       "1        1  51.176056   89.244780\n",
       "2        2  66.510903   89.422360\n",
       "3        3  54.037752   87.408734\n",
       "4        4  60.554520   89.281855\n",
       "5        5  51.037406   89.003111\n",
       "6        6  63.092680   89.463496\n",
       "7        7  57.049152   89.459365\n",
       "8        8  42.237874   86.087905"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table= df.groupby('topic',as_index=False)[['price','points']].mean()\n",
    "table.rename(columns={'topic':'cluster','price':'Avg_price','points':'Avg_points'}, inplace=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
